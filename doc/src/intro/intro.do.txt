TITLE: Introduction to the FRIB-TA Summer School: Quantum Computing and Nuclear Few- and Many-Body Problems with teaching plan and learning outcomes
AUTHOR: Facility for Rare Isotope Beams, Michigan State University, USA
DATE: June 20



===== Introduction =====

Recent developments in quantum information systems and technologies
offer the possibility to address some of the most challenging
large-scale problems in science, whether they are represented by
complicated interacting quantum mechanical systems or classical
systems. The last years have seen a rapid and exciting development in
algorithms and quantum hardware.  The emphasis of this summer school
is to highlight, through a series of lectures and hands-on exercises
and practice sessions, how quantum computing algorithms can be used to
study nuclear few- and many-body problems of relevance for low-energy
nuclear physics.  And how quantum computing algorithms can aid in
studying systems with increasingly many more degrees of freedom
compared with more classical few- and many-body methods.  Several
quantum algorithms for solving quantum-mechanical few- and
many-particle problems with be discussed.  The lectures will start
with the basic ideas of quantum computing. Thereafter, through
examples from nuclear physics, we will elucidate how different quantum
algorithms can be used to study these systems. The results from
various quantum computing algorithms will be compared to standard
nuclear few- and many-body methods 

=== Organizers: ===
Alexei Bazavov (MSU), Scott Bogner (MSU), Heiko Hergert (MSU), Matthew Hirn (MSU), Morten Hjorth-Jensen (MSU), Dean Lee (MSU), Huey-Wen Lin (MSU), and Andrea Shindler (MSU)

Contact person: Morten Hjorth-Jensen, hjensen@msu.edu

=== Additional material in these slides ===

In addition to containing information about the school, we provide a reminder on _numpy_ and a brief introduction to Qiskit. Please take a look at these notes before coming to the school. This material is provided at the end of the these introductory notes.



===== Aims and Learning Outcomes =====

=== The following topics will be covered ===
o Basic elements of quantum computing (first day) with introduction to relevant software, including
   o Introduction to quantum computing, qubits and systems of qubits
   o Measurements, Superposition and Entanglement
   o Gates, unitary transformations and quantum circuits
   o Quantum algorithms and implementation on a real quantum computer

o Simulating quantum-mechanical few- and many-body systems
   o Quantum algorithms for quantum mechanical systems
   o Quantum simulation of the Schroedinger equation
   o Quantum computing and nuclear few- and many-body systems
   o Quantum state preparation and Quantum simulations
   o Quantum simulations on a real quantum computer

o Quantum field theory and quantum computing
o Noise, error correction and mitigation

All of the above topics will be supported by examples, hands-on exercises and project work.


=====  Practicalities =====

o Lectures Monday through Wednesday, starting at 830am, see schedule below
o Hands-on sessions before lunch and in the afternoons till 6pm
o For all lecture days we provide relevant jupyter-notebooks you can work on


===== Learning material and resources =====
o Qiskit textbook, free online, see URL:"https://qiskit.org/textbook/preface.html"
o Scherer, The Mathematics of Quantum Computing, see URL:"https://link.springer.com/book/10.1007/978-3-030-12358-1"
o Chuang and Nielsen, Quantum Computation and Quantum Information, URL:"https://www.cambridge.org/highereducation/books/quantum-computation-and-quantum-information/01E10196D0A682A6AEFFEA52D53BE9AE#overview"
o Hundt, Quantum Computing for programmers, URL:"https://www.cambridge.org/core/books/quantum-computing-for-programmers/BA1C887BE4AC0D0D5653E71FFBEF61C6"

===  Good resources ===
With the hands-on programming component we strongly recommend that you install Qiskit on your computer before the school starts. 
o For Qiskit, follow the  instructions at URL:"https://qiskit.org/documentation/getting_started.html"
o We strongly recommend using the Jupyter notebook environment at URL:"https://quantum-computing.ibm.com/". This environment has Qiskit already set up and is free,  just requires an email to register. It has built in support for Jupyter notebooks and should be sufficient for everything needed.
o See also Ryan Larose's (from 2019) Quantum computing bootcamp with Qiskit - URL:"https://github.com/rmlarose/qcbq."
o See also URL:"https://www.ryanlarose.com/external-resources.html"


=== Scientific articles of interest ===
o Adam Smith, M. S. Kim, Frank Pollmann, and Johannes Knolle, Simulating quantum many-body dynamics on a current digital quantum computer, NPJ Quantum Information 5, Article number: 106 (2019), see URL:"https://www.nature.com/articles/s41534-019-0217-0"


=====  Detailed lecture plan  =====

The duration of each lecture is approximately 45-50 minutes and there
is a small break of 10-15 minutes between each lecture. Longer breaks
at 1030am-11am and 3pm-330pm, except for Monday where there is also
the possibility fora guided FRIB tour.  In-person attendance is the
main teaching modus, but lectures and hands-on sessions will be
broadcasted via zoom for those who cannot attend in person. The zoom
link will be sent to those who have expressed that they cannot attend
in person. The lectures will also be recorded.


===  Teachers ===
* AB = Alexei Bazavov
* BH = Benjamin Hall
* DJ = Danny Jammoa (online discussions and hands-on sessions)
* DL = Dean Lee
* JW = Jacob Watkins
* JB = Joey Bonitati
* MHJ = Morten Hjorth-Jensen
* RL = Ryan Larose
* QZ - Zhenrong Qian



===  Monday June 20  ===
* 8am-830am: Welcome and registration
* 830am-930am: "Introduction to quantum computing, qubits, systems of qubits, gates and quantum circuits (AB)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 930am-1030am: "Measurements, Superposition, Entanglement (AB)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 1030am-11am: Break, coffee, tea etc
* 11am-12pm: "Hands-on session with applications and introduction to software libraries (AB, JW, RL)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 12pm-1pm: Lunch (shorter lunch, else 1h30m lunches)
* 1pm-2pm: "Algorithms for quantum dynamics (DL), simple problems":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 2pm-3pm: "Quantum phase estimation and adiabatic evolution (ZQ and JB), simple problems":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 3pm-4pm: Break, coffee, tea or tour for FRIB for those interested. Please let us know if you are interested in a tour of FRIB.
* 4pm-6pm: "Hands-on sessions and problem solving (AB+all)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"

=== Tuesday June 21 ===
* 830-930am: "Hamiltonian simulation: a general overview (JW)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 930am-1030am: "Introduction to VQE and simple model (BH)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html" 
* 1030am-11am: Break, coffee, tea etc
* 11am-12pm: "Many-body theory and nuclear few- and many-body systems (BH and MHJ)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 12pm-130pm: Lunch
* 130pm-230pm:  "Quantum algorithms (VQE) and nuclear physics with applications (BH and MHJ), part 1":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 230pm-330pm:  "Quantum algorithms (VQE) and nuclear physics with applications (BH and MHJ), part 2":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 330pm-4pm: Break, coffee, tea etc
* 4pm-6pm: "Hands-on sessions and problem solving (BH and JW+all)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"

=== Wednesday June 22 ===
* 830am-930am: "Noise, error correction and mitigation, part I (RL)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 930am-1030am: "Noise, error correction and mitigation, part II (RL)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 1030am-11am: Break, coffee, tea etc
* 11am-12pm: "Practicing error correction and mitigation, hands-on part (RL)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 12pm-130pm: Lunch
* 130pm-230pm: "Wrapping up and defining nuclear many-body system to study for hands-on session (All)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 230pm-330pm: "Start hands-on session (RL)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"
* 330pm-4pm: Break, coffee, tea etc
* 4pm-6pm: "Hands-on sessions and problem solving (all)":"https://nuclearphysicsworkshops.github.io/FRIB-TASummerSchoolQuantumComputing/doc/web/course.html"



===== Prerequisites =====

You are expected to have operating programming skills in programming
languages like Python (preferred) and/or Fortran, C++, Julia or
similar and knowledge of quantum mechanics at an intermediate level
(senior undergraduate and/or beginning graduate). Knowledge of linear
algebra is essential.  Additional modules for self-teaching on Python
and quantum mechanics are also provided. 





===== Software and needed installations =====

We will make extensive use of Python as programming language and its
myriad of available libraries.  You will find
Jupyter notebooks invaluable in your work.

If you have Python installed (we strongly recommend Python3) and you feel
pretty familiar with installing different packages, we recommend that
you install the following Python packages via _pip_ as 

o pip install numpy scipy matplotlib ipython scikit-learn mglearn sympy pandas pillow 

For Python3, replace _pip_ with _pip3_.

For OSX users we recommend, after having installed Xcode, to
install _brew_. Brew allows for a seamless installation of additional
software via for example 

o brew install python3

For Linux users, with its variety of distributions like for example the widely popular Ubuntu distribution,
you can use _pip_ as well and simply install Python as 

o sudo apt-get install python3  (or python for pyhton2.7)

etc etc. 



===== Python installers =====

If you don't want to perform these operations separately and venture
into the hassle of exploring how to set up dependencies and paths, we
recommend two widely used distrubutions which set up all relevant
dependencies for Python, namely 

* "Anaconda":"https://docs.anaconda.com/", 

which is an open source
distribution of the Python and R programming languages for large-scale
data processing, predictive analytics, and scientific computing, that
aims to simplify package management and deployment. Package versions
are managed by the package management system _conda_. 

* "Enthought canopy":"https://www.enthought.com/product/canopy/" 

is a Python
distribution for scientific and analytic computing distribution and
analysis environment, available for free and under a commercial
license.

Furthermore, "Google's Colab":"https://colab.research.google.com/notebooks/welcome.ipynb" is a free Jupyter notebook environment that requires 
no setup and runs entirely in the cloud. Try it out!

===== Useful Python libraries =====
Here we list several useful Python libraries we strongly recommend (if you use anaconda many of these are already there)

* "NumPy":"https://www.numpy.org/" is a highly popular library for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays
* "The pandas":"https://pandas.pydata.org/" library provides high-performance, easy-to-use data structures and data analysis tools 
* "Xarray":"http://xarray.pydata.org/en/stable/" is a Python package that makes working with labelled multi-dimensional arrays simple, efficient, and fun!
* "Scipy":"https://www.scipy.org/" (pronounced “Sigh Pie”) is a Python-based ecosystem of open-source software for mathematics, science, and engineering. 
* "Matplotlib":"https://matplotlib.org/" is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.
* "Autograd":"https://github.com/HIPS/autograd" can automatically differentiate native Python and Numpy code. It can handle a large subset of Python's features, including loops, ifs, recursion and closures, and it can even take derivatives of derivatives of derivatives
* "SymPy":"https://www.sympy.org/en/index.html" is a Python library for symbolic mathematics. 
* "scikit-learn":"https://scikit-learn.org/stable/" has simple and efficient tools for machine learning, data mining and data analysis
* "TensorFlow":"https://www.tensorflow.org/" is a Python library for fast numerical computing created and released by Google
* "Keras":"https://keras.io/" is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano
* And many more such as "pytorch":"https://pytorch.org/",  "Theano":"https://pypi.org/project/Theano/" etc 


All learning material and teaching schedule pertinent to the course is
avaliable at this GitHub address. A simple _git clone_ of the material
gives you access to all lecture notes and program examples. Similarly,
running a _git pull_ gives you immediately the latest updates.



!split
===== Numpy examples and Important Matrix and vector handling packages =====

There are several central software libraries for linear algebra and eigenvalue problems. Several of the more
popular ones have been wrapped into ofter software packages like those from the widely used text _Numerical Recipes_. The original source codes in many of the available packages are often taken from the widely used
software package LAPACK, which follows two other popular packages
developed in the 1970s, namely EISPACK and LINPACK.  We describe them shortly here.

  * LINPACK: package for linear equations and least square problems.
  * LAPACK:package for solving symmetric, unsymmetric and generalized eigenvalue problems. From LAPACK's website URL: "http://www.netlib.org" it is possible to download for free all source codes from this library. Both C/C++ and Fortran versions are available.
  * BLAS (I, II and III): (Basic Linear Algebra Subprograms) are routines that provide standard building blocks for performing basic vector and matrix operations. Blas I is vector operations, II vector-matrix operations and III matrix-matrix operations. Highly parallelized and efficient codes, all available for download from URL: "http://www.netlib.org".

!split
===== Basic Matrix Features =====

!bblock Matrix properties reminder
!bt
\[
 \mathbf{A} =
      \begin{bmatrix} a_{11} & a_{12} & a_{13} & a_{14} \\
                                 a_{21} & a_{22} & a_{23} & a_{24} \\
                                   a_{31} & a_{32} & a_{33} & a_{34} \\
                                  a_{41} & a_{42} & a_{43} & a_{44}
             \end{bmatrix}\qquad
\mathbf{I} =
      \begin{bmatrix} 1 & 0 & 0 & 0 \\
                                 0 & 1 & 0 & 0 \\
                                 0 & 0 & 1 & 0 \\
                                 0 & 0 & 0 & 1
             \end{bmatrix}
\]
!et



The inverse of a matrix is defined by

!bt
\[
\mathbf{A}^{-1} \cdot \mathbf{A} = I
\]
!et


|----------------------------------------------------------------------|
|       Relations      |       Name      | matrix elements             |
|----------------------------------------------------------------------|
| $A=A^{T}$         | symmetric       | $a_{ij}=a_{ji}$            |
| $A=\left (A^{T}\right )^{-1}$ | real orthogonal | $\sum_k a_{ik}a_{jk}=\sum_k a_{ki} a_{kj}=\delta_{ij}$ |
| $A=A^{ * }$          | real matrix     | $a_{ij}=a_{ij}^{*}$       |
| $A=A^{\dagger}$     |  hermitian      | $a_{ij}=a_{ji}^{*}$       |
| $A=\left(A^{\dagger}\right )^{-1}$ | unitary | $\sum_k a_{ik}a_{jk}^{*}=\sum_k a_{ki}^{ * } a_{kj}=\delta_{ij}$ |
|----------------------------------------------------------------------|

!eblock

!split
=== Some famous Matrices ===

  * Diagonal if $a_{ij}=0$ for $i\ne j$
  * Upper triangular if $a_{ij}=0$ for $i>j$
  * Lower triangular if $a_{ij}=0$ for $i<j$
  * Upper Hessenberg if $a_{ij}=0$ for $i>j+1$
  * Lower Hessenberg if $a_{ij}=0$ for $i<j+1$
  * Tridiagonal if $a_{ij}=0$ for $|i -j|>1$
  * Lower banded with bandwidth $p$: $a_{ij}=0$ for $i>j+p$
  * Upper banded with bandwidth $p$: $a_{ij}=0$ for $i<j+p$
  * Banded, block upper triangular, block lower triangular....


!split
=== More Basic Matrix Features ===

!bblock Some Equivalent Statements
For an $N\times N$ matrix  $\mathbf{A}$ the following properties are all equivalent

  * If the inverse of $\mathbf{A}$ exists, $\mathbf{A}$ is nonsingular.
  * The equation $\mathbf{Ax}=0$ implies $\mathbf{x}=0$.
  * The rows of $\mathbf{A}$ form a basis of $R^N$.
  * The columns of $\mathbf{A}$ form a basis of $R^N$.
  * $\mathbf{A}$ is a product of elementary matrices.
  * $0$ is not eigenvalue of $\mathbf{A}$.
!eblock

!split
===== Numpy and arrays =====
"Numpy":"http://www.numpy.org/" provides an easy way to handle arrays in Python. The standard way to import this library is as

!bc pycod
import numpy as np
!ec
Here follows a simple example where we set up an array of ten elements, all determined by random numbers drawn according to the normal distribution,
!bc pycod
n = 10
x = np.random.normal(size=n)
print(x)
!ec
We defined a vector $x$ with $n=10$ elements with its values given by the Normal distribution $N(0,1)$.
Another alternative is to declare a vector as follows
!bc pycod
import numpy as np
x = np.array([1, 2, 3])
print(x)
!ec
Here we have defined a vector with three elements, with $x_0=1$, $x_1=2$ and $x_2=3$. Note that both Python and C++
start numbering array elements from $0$ and on. This means that a vector with $n$ elements has a sequence of entities $x_0, x_1, x_2, \dots, x_{n-1}$. We could also let (recommended) Numpy to compute the logarithms of a specific array as
!bc pycod
import numpy as np
x = np.log(np.array([4, 7, 8]))
print(x)
!ec

In the last example we used Numpy's unary function $np.log$. This function is
highly tuned to compute array elements since the code is vectorized
and does not require looping. We normaly recommend that you use the
Numpy intrinsic functions instead of the corresponding _log_ function
from Python's _math_ module. The looping is done explicitely by the
_np.log_ function. The alternative, and slower way to compute the
logarithms of a vector would be to write

!bc pycod
import numpy as np
from math import log
x = np.array([4, 7, 8])
for i in range(0, len(x)):
    x[i] = log(x[i])
print(x)
!ec
We note that our code is much longer already and we need to import the _log_ function from the _math_ module. 
The attentive reader will also notice that the output is $[1, 1, 2]$. Python interprets automagically our numbers as integers (like the _automatic_ keyword in C++). To change this we could define our array elements to be double precision numbers as
!bc pycod
import numpy as np
x = np.log(np.array([4, 7, 8], dtype = np.float64))
print(x)
!ec
or simply write them as double precision numbers (Python uses 64 bits as default for floating point type variables), that is
!bc pycod
import numpy as np
x = np.log(np.array([4.0, 7.0, 8.0]))
print(x)
!ec
To check the number of bytes (remember that one byte contains eight bits for double precision variables), you can use simple use the _itemsize_ functionality (the array $x$ is actually an object which inherits the functionalities defined in Numpy) as 
!bc pycod
import numpy as np
x = np.log(np.array([4.0, 7.0, 8.0]))
print(x.itemsize)
!ec

!split
===== Matrices in Python =====

Having defined vectors, we are now ready to try out matrices. We can
define a $3 \times 3 $ real matrix $\bm{A}$ as (recall that we user
lowercase letters for vectors and uppercase letters for matrices)

!bc pycod
import numpy as np
A = np.log(np.array([ [4.0, 7.0, 8.0], [3.0, 10.0, 11.0], [4.0, 5.0, 7.0] ]))
print(A)
!ec
If we use the _shape_ function we would get $(3, 3)$ as output, that is verifying that our matrix is a $3\times 3$ matrix. We can slice the matrix and print for example the first column (Python organized matrix elements in a row-major order, see below) as
!bc pycod
import numpy as np
A = np.log(np.array([ [4.0, 7.0, 8.0], [3.0, 10.0, 11.0], [4.0, 5.0, 7.0] ]))
# print the first column, row-major order and elements start with 0
print(A[:,0]) 
!ec
We can continue this way by printing out other columns or rows. The example here prints out the second column
!bc pycod
import numpy as np
A = np.log(np.array([ [4.0, 7.0, 8.0], [3.0, 10.0, 11.0], [4.0, 5.0, 7.0] ]))
# print the first column, row-major order and elements start with 0
print(A[1,:]) 
!ec 
Numpy contains many other functionalities that allow us to slice, subdivide etc etc arrays. We strongly recommend that you look up the "Numpy website for more details":"http://www.numpy.org/". Useful functions when defining a matrix are the _np.zeros_ function which declares a matrix of a given dimension and sets all elements to zero
!bc pycod
import numpy as np
n = 10
# define a matrix of dimension 10 x 10 and set all elements to zero
A = np.zeros( (n, n) )
print(A) 
!ec 
or initializing all elements to 
!bc pycod
import numpy as np
n = 10
# define a matrix of dimension 10 x 10 and set all elements to one
A = np.ones( (n, n) )
print(A) 
!ec 
or as unitarily distributed random numbers
!bc pycod
import numpy as np
n = 10
# define a matrix of dimension 10 x 10 and set all elements to random numbers with x \in [0, 1]
A = np.random.rand(n, n)
print(A) 
!ec 

There are several other extremely useful functionalities in Numpy. Numpy contains many functions which are useful if we wish to perform a statistical analysis.
As an example, consider the discussion of the covariance matrix. Suppose we have defined three vectors
$\bm{x}, \bm{y}, \bm{z}$ with $n$ elements each. The covariance matrix is defined as 
!bt
\[
\bm{\Sigma} = \begin{bmatrix} \sigma_{xx} & \sigma_{xy} & \sigma_{xz} \\
                              \sigma_{yx} & \sigma_{yy} & \sigma_{yz} \\
                              \sigma_{zx} & \sigma_{zy} & \sigma_{zz} 
             \end{bmatrix},
\]
!et
where for example
!bt
\[
\sigma_{xy} =\frac{1}{n} \sum_{i=0}^{n-1}(x_i- \overline{x})(y_i- \overline{y}).
\]
!et
The Numpy function _np.cov_ calculates the covariance elements using the factor $1/(n-1)$ instead of $1/n$ since it assumes we do not have the exact mean values. 
The following simple function uses the _np.vstack_ function which takes each vector of dimension $1\times n$ and produces a $3\times n$ matrix $\bm{W}$
!bt
\[
\bm{W} = \begin{bmatrix} x_0 & x_1 & x_2 & \dots & x_{n-2} & x_{n-1} \\
                         y_0 & y_1 & y_2 & \dots & y_{n-2} & y_{n-1} \\
			 z_0 & z_1 & z_2 & \dots & z_{n-2} & z_{n-1} \\
             \end{bmatrix},
\]
!et

which in turn is converted into into the $3\times 3$ covariance matrix
$\bm{\Sigma}$ via the Numpy function _np.cov()_. We note that we can also calculate
the mean value of each set of samples $\bm{x}$ etc using the Numpy
function _np.mean(x)_. We can also extract the eigenvalues of the
covariance matrix through the _np.linalg.eig()_ function.

!bc pycod
# Importing various packages
import numpy as np

n = 100
x = np.random.normal(size=n)
print(np.mean(x))
y = 4+3*x+np.random.normal(size=n)
print(np.mean(y))
z = x**3+np.random.normal(size=n)
print(np.mean(z))
W = np.vstack((x, y, z))
Sigma = np.cov(W)
print(Sigma)
Eigvals, Eigvecs = np.linalg.eig(Sigma)
print(Eigvals)
!ec


!bc pycod
import numpy as np
import matplotlib.pyplot as plt
from scipy import sparse
eye = np.eye(4)
print(eye)
sparse_mtx = sparse.csr_matrix(eye)
print(sparse_mtx)
x = np.linspace(-10,10,100)
y = np.sin(x)
plt.plot(x,y,marker='x')
plt.show()
!ec

!split
===== Meet the Pandas =====


Another useful Python package is
"pandas":"https://pandas.pydata.org/", which is an open source library
providing high-performance, easy-to-use data structures and data
analysis tools for Python. _pandas_ stands for panel data, a term borrowed from econometrics and is an efficient library for data analysis with an emphasis on tabular data.
_pandas_ has two major classes, the _DataFrame_ class with two-dimensional data objects and tabular data organized in columns and the class _Series_ with a focus on one-dimensional data objects. Both classes allow you to index data easily as we will see in the examples below. 
_pandas_ allows you also to perform mathematical operations on the data, spanning from simple reshapings of vectors and matrices to statistical operations. 

The following simple example shows how we can, in an easy way make tables of our data. Here we define a data set which includes names, place of birth and date of birth, and displays the data in an easy to read way. 

!bc pycod 
import pandas as pd
from IPython.display import display
data = {'First Name': ["Frodo", "Bilbo", "Aragorn II", "Samwise"],
        'Last Name': ["Baggins", "Baggins","Elessar","Gamgee"],
        'Place of birth': ["Shire", "Shire", "Eriador", "Shire"],
        'Date of Birth T.A.': [2968, 2890, 2931, 2980]
        }
data_pandas = pd.DataFrame(data)
display(data_pandas)
!ec

In the above we have imported _pandas_ with the shorthand _pd_, the latter has become the standard way we import _pandas_. We make then a list of various variables
and reorganize the aboves lists into a _DataFrame_ and then print out  a neat table with specific column labels as *Name*, *place of birth* and *date of birth*.
Displaying these results, we see that the indices are given by the default numbers from zero to three.
_pandas_ is extremely flexible and we can easily change the above indices by defining a new type of indexing as
!bc pycod
data_pandas = pd.DataFrame(data,index=['Frodo','Bilbo','Aragorn','Sam'])
display(data_pandas)
!ec
Thereafter we display the content of the row which begins with the index _Aragorn_
!bc pycod
display(data_pandas.loc['Aragorn'])
!ec

We can easily append data to this, for example
!bc pycod
new_hobbit = {'First Name': ["Peregrin"],
              'Last Name': ["Took"],
              'Place of birth': ["Shire"],
              'Date of Birth T.A.': [2990]
              }
data_pandas=data_pandas.append(pd.DataFrame(new_hobbit, index=['Pippin']))
display(data_pandas)
!ec


Here are other examples where we use the _DataFrame_ functionality to handle arrays, now with more interesting features for us, namely numbers. We set up a matrix 
of dimensionality $10\times 5$ and compute the mean value and standard deviation of each column. Similarly, we can perform mathematial operations like squaring the matrix elements and many other operations. 
!bc pycod
import numpy as np
import pandas as pd
from IPython.display import display
np.random.seed(100)
# setting up a 10 x 5 matrix
rows = 10
cols = 5
a = np.random.randn(rows,cols)
df = pd.DataFrame(a)
display(df)
print(df.mean())
print(df.std())
display(df**2)
!ec

Thereafter we can select specific columns only and plot final results
!bc pycod
df.columns = ['First', 'Second', 'Third', 'Fourth', 'Fifth']
df.index = np.arange(10)

display(df)
print(df['Second'].mean() )
print(df.info())
print(df.describe())

from pylab import plt, mpl
plt.style.use('seaborn')
mpl.rcParams['font.family'] = 'serif'

df.cumsum().plot(lw=2.0, figsize=(10,6))
plt.show()


df.plot.bar(figsize=(10,6), rot=15)
plt.show()
!ec
We can produce a $4\times 4$ matrix
!bc pycod
b = np.arange(16).reshape((4,4))
print(b)
df1 = pd.DataFrame(b)
print(df1)
!ec
and many other operations. 

The _Series_ class is another important class included in
_pandas_. You can view it as a specialization of _DataFrame_ but where
we have just a single column of data. It shares many of the same features as _DataFrame. As with _DataFrame_,
most operations are vectorized, achieving thereby a high performance when dealing with computations of arrays, in particular labeled arrays.

For multidimensional arrays, we recommend strongly "xarray":"http://xarray.pydata.org/en/stable/". _xarray_ has much of the same flexibility as _pandas_, but allows for the extension to higher dimensions than two. We will see examples later of the usage of both _pandas_ and _xarray_. 


